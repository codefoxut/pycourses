{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7def5de4-488a-4d1a-a4e6-a692cb27b71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733fe750-b545-4d5a-bc01-0548dd4d898b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "# From Spacy Basics:\n",
    "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d24653d-339d-42be-bd5d-2ef54f0c3e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    }
   ],
   "source": [
    "print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc955413-29f2-4bca-bd97-a584c0eb50be",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(doc.sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f582476d-8a29-4b49-961b-a0f39569ee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([This is the first sentence.,\n",
       "  This is another sentence.,\n",
       "  This is the last sentence.],\n",
       " [This is the first sentence.,\n",
       "  This is another sentence.,\n",
       "  This is the last sentence.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [sent for sent in doc.sents]\n",
    "\n",
    "doc_sen = list(doc.sents)\n",
    "doc_sents, doc_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ec744d-bbcd-4bb3-9303-57e314f229ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is another sentence.\n"
     ]
    }
   ],
   "source": [
    "print(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dc485ed-47c1-41b5-8069-f317d6a4c426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0c36791-46f4-4b58-8530-af833902b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 11\n"
     ]
    }
   ],
   "source": [
    "print(doc_sents[1].start, doc_sents[1].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec39d7fc-f111-4b72-b8cc-cfa1ed5bfbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n"
     ]
    }
   ],
   "source": [
    "# Parsing the segmentation start tokens happens during the nlp pipeline\n",
    "doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence.')\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.is_sent_start, ' '+token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52af2305-bd70-486d-9483-c61c1cd06c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# SPACY'S DEFAULT BEHAVIOR\n",
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88421b37-7d03-4875-9856-3095698aed59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD A NEW RULE TO THE PIPELINE\n",
    "from spacy.language import Language\n",
    "@Language.component(\"custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"custom_boundaries\", before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66bbb3e1-f9d1-43cf-a73c-7bcf727e9283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# Re-run the Doc object creation:\n",
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0082e696-5fe8-459b-8fb9-ac44247bbbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "# And yet the new rule doesn't apply to the older Doc object:\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61d474b2-63c0-44d6-9719-7b13c89bdc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leadership"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e66bb61-3293-49d1-9b2b-22e0088a758f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Try to change the .is_sent_start attribute:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdoc3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_sent_start\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/codingpoint/pycourses/venvnlp/lib/python3.11/site-packages/spacy/tokens/token.pyx:535\u001b[0m, in \u001b[0;36mspacy.tokens.token.Token.is_sent_start.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E043] Refusing to write to token.sent_start if its document is parsed, because this may cause inconsistent state."
     ]
    }
   ],
   "source": [
    "# Try to change the .is_sent_start attribute:\n",
    "doc3[7].is_sent_start = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b06ad19-63aa-4835-865b-0e6a315e7326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sentence', '.']\n",
      "['This', 'is', 'another', '.', '\\n\\n']\n",
      "['This', 'is', 'a', '\\n', 'third', 'sentence', '.']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')  # reset to the original\n",
    "\n",
    "mystring = u\"This is a sentence. This is another.\\n\\nThis is a \\nthird sentence.\"\n",
    "\n",
    "# SPACY DEFAULT BEHAVIOR:\n",
    "doc = nlp(mystring)\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b9490e3-bb8d-4f0b-8ce3-e12743317256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.split_on_newlines(doc)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHANGING THE RULES\n",
    "\n",
    "from spacy.language import Language\n",
    "@Language.component(\"custom_segmenter\")\n",
    "def split_on_newlines(doc):\n",
    "    start = 0\n",
    "    seen_newline = False\n",
    "    for word in doc:\n",
    "        if seen_newline:\n",
    "            yield doc[start:word.i]\n",
    "            start = word.i\n",
    "            seen_newline = False\n",
    "        elif word.text.startswith('\\n'): # handles multiple occurrences\n",
    "            seen_newline = True\n",
    "    yield doc[start:]      # handles the last group of tokens\n",
    "\n",
    "\n",
    "\n",
    "nlp.add_pipe(\"custom_segmenter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95662272-6a15-424d-93f6-27074b642928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "nlp.add_pipe(\"rest_countries\", config={\"label\": \"GPE\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56bdf017-8d77-444f-ba4e-e84220a879c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E005] Pipeline component 'custom_segmenter' returned <class 'generator'> instead of a Doc. If you're using a custom component, maybe you forgot to return the processed Doc?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmystring\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m([token\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m sent])\n",
      "File \u001b[0;32m~/codingpoint/pycourses/venvnlp/lib/python3.11/site-packages/spacy/language.py:1056\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1054\u001b[0m         error_handler(name, proc, [doc], e)\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc, Doc):\n\u001b[0;32m-> 1056\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE005\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, returned_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc)))\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "\u001b[0;31mValueError\u001b[0m: [E005] Pipeline component 'custom_segmenter' returned <class 'generator'> instead of a Doc. If you're using a custom component, maybe you forgot to return the processed Doc?"
     ]
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "for sent in doc.sents:\n",
    "    print([token.text for token in sent])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cf930-640b-44e6-8e00-ef134e9bc47a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
